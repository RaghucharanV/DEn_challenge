{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1\n",
    "A.Data Source\n",
    "(videocapture)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate the ingestion of a live video stream using Python. You can use libraries like OpenCV to read video frames from a video file. Consider that as a live stream and provide code to capture frames continuously from the source.\n",
    "\n",
    "\n",
    "2. Frame Processing\n",
    "Develop a function or class that takes each incoming video frame and performs the\n",
    "following actions:\n",
    "a. Frame by frame process and create a json object for each frame.\n",
    "\n",
    "b. Extract relevant information from the processed frame. The json must contain the\n",
    "following information:\n",
    "i. camera_id\n",
    "ii. frame_id\n",
    "iii. geo_location\n",
    "iv. image_path (write the frames as jpg image file)\n",
    "\n",
    "\n",
    "c. Consider that the streaming is 25 FPS. Hence for every second write any one frame\n",
    "as an image file and reuse that file for the rest 24 frames. Hence it is enough to write\n",
    "only one frame per second as an image file.\n",
    "\n",
    "\n",
    "D. Simultaneously while processing frames, all the frame information must be written in a\n",
    "json file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Batching\n",
    "As mentioned earlier, the duration of the video file (in secs) will be mentioned in the\n",
    "config file. Based on the duration value, perform batching of above processed frameâ€™s\n",
    "information. Create a dictionary for every batch that consists of following keys:\n",
    "i. batch_id\n",
    "ii. starting_frame_id\n",
    "iii. ending_frame_id\n",
    "iv. timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, In below class, Impelemented Task 1, First Three things, followed by applying conditions.\n",
    "\n",
    "Every fuction is well commented to know. To end video Stream press \"q\" key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame processing and batching complete. JSON data saved to: frame_info.json\n",
      "Batch information saved to: batch_info.json\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import pyodbc\n",
    "\n",
    "#Creating video-Streaming class\n",
    "class VideoStreaming:\n",
    "    def __init__(self, camera_id, geo_location, output_folder, config_filename):\n",
    "        self.camera_id = camera_id\n",
    "        self.geo_location = geo_location\n",
    "        self.output_folder = output_folder\n",
    "        self.frame_id = 0\n",
    "        self.cap = cv2.VideoCapture(camera_id)\n",
    "        self.config_filename = config_filename\n",
    "        self.batch_duration = self.read_config_duration()[0]\n",
    "        self.batch_size = self.read_config_duration()[1]\n",
    "        \n",
    "        # Create the output folder\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        #JSON data list and batch list\n",
    "        self.json_data = []\n",
    "        self.batches = []\n",
    "\n",
    "    def read_config_duration(self):\n",
    "        # Read the duration from the config file\n",
    "        with open(self.config_filename, \"r\") as config_file:\n",
    "            config_data = json.load(config_file)\n",
    "            duration = config_data.get(\"duration\")\n",
    "            batch_size = config_data.get(\"batch_size\")\n",
    "        return duration,batch_size\n",
    "\n",
    "    def video_capture(self):\n",
    "        # Check if the video stream was opened successfully\n",
    "        if not self.cap.isOpened():\n",
    "            exit()\n",
    "\n",
    "    def frame_processing(self):\n",
    "        # Set the desired frames per second (fps) based on condition\n",
    "        desired_fps = 25\n",
    "        frame_count = 0\n",
    "        frame_to_save = None\n",
    "\n",
    "        while True:\n",
    "            # Read a frame from the video stream\n",
    "            ret, frame = self.cap.read()\n",
    "\n",
    "            # Check if the frame was successfully read\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "            # Save one frame per second as an image file\n",
    "            if frame_count % desired_fps == 0:\n",
    "                outframe_id = (frame_count // desired_fps)\n",
    "                frame_to_save = frame  # Save the frame to be reused\n",
    "                frame_filename = os.path.join(self.output_folder, f\"frame_{outframe_id}.jpg\")\n",
    "                cv2.imwrite(frame_filename, frame_to_save)  # Save the frame as an image\n",
    "\n",
    "                # Append frame info to the JSON data list\n",
    "                frame_info = {\n",
    "                    \"camera_id\": self.camera_id,\n",
    "                    \"frame_id\": outframe_id,\n",
    "                    \"geo_location\": self.geo_location,\n",
    "                    \"image_path\": frame_filename\n",
    "                }\n",
    "                self.json_data.append(frame_info)\n",
    "\n",
    "            # Reuse the saved frame for the next 24 frames within the same second\n",
    "            if frame_to_save is not None:\n",
    "                cv2.imshow(\"Frame\", frame_to_save)\n",
    "\n",
    "            # Exit the loop when the 'q' key is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            # Release the video capture object and close any open windows\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def batch_frames(self):     \n",
    "    # Calculate the number of batches.\n",
    "        num_batches = math.ceil(self.batch_duration / self.batch_size)\n",
    "\n",
    "    # Create a dictionary for each batch.\n",
    "        #batches = {}\n",
    "        for i in range(num_batches):\n",
    "            batch_id = i + 1\n",
    "\n",
    "        # Calculate the starting and ending frame IDs for the batch.\n",
    "            starting_frame_id = batch_id * self.batch_size - self.batch_size + 1\n",
    "            ending_frame_id = min(starting_frame_id + self.batch_size - 1, self.batch_duration)\n",
    "\n",
    "        # Calculate the timestamp of the batch.\n",
    "            timestamp = starting_frame_id / self.batch_duration\n",
    "        #timestamp = time.time()\n",
    "\n",
    "        # Add the batch to the dictionary.\n",
    "            batch = {\n",
    "            \"batch_id\": batch_id,\n",
    "            \"starting_frame_id\": starting_frame_id,\n",
    "            \"ending_frame_id\": ending_frame_id,\n",
    "            \"timestamp\": timestamp\n",
    "            }\n",
    "            self.batches.append(batch)\n",
    "            return self.batches\n",
    "        \n",
    "    def save_json_data(self, json_filename):\n",
    "        # Write JSON data to a JSON file\n",
    "        with open(json_filename, \"w\") as json_file:\n",
    "            json.dump(self.json_data, json_file, indent=4)\n",
    "\n",
    "    def save_batch_info(self, batch_filename):\n",
    "        with open(batch_filename, \"w\") as batch_file:\n",
    "            json.dump(self.batches, batch_file, indent=4)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    camera_id = 0\n",
    "    geo_location = \"latitude: 123.456, longitude: 789.012\"\n",
    "    output_folder = \"output_frames\"\n",
    "    config_filename = \"config.json\"\n",
    "    json_filename = \"frame_info.json\"\n",
    "    batch_filename = \"batch_info.json\"\n",
    "\n",
    "    processor = VideoStreaming(camera_id, geo_location, output_folder, config_filename)\n",
    "    processor.video_capture()\n",
    "    processor.frame_processing()\n",
    "    processor.batch_frames()\n",
    "    processor.save_json_data(json_filename)\n",
    "    processor.save_batch_info(batch_filename)\n",
    "\n",
    "\n",
    "    print(\"Frame processing and batching complete. JSON data saved to:\", json_filename)\n",
    "    print(\"Batch information saved to:\", batch_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data Storage\n",
    "Use any SQL Database and create necessary tables and columns to store batch\n",
    "information. Every batch information must be logged in the DB.\n",
    "\n",
    "here, I used local postgresql as to store data in a database table for every batch infomation of video stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import psycopg2\n",
    "\n",
    "#create a connection to database;\n",
    "conncetion = psycopg2.connect(dbname=\"videostream\",user=\"postgres\",password=\"leo@#838\",host=\"localhost\",port=5432)\n",
    "\n",
    "\n",
    "# Create a cursor object for executing SQL queries\n",
    "cursor = conncetion.cursor()\n",
    "\n",
    "with open('batch_info.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Define the INSERT SQL statement\n",
    "sql_insert = \"INSERT INTO logfiles (batch_id, starting_frame_id, ending_frame_id,timestamp) VALUES (%s, %s, %s, %s)\"\n",
    "\n",
    "# Insert records from the JSON data\n",
    "for record in data:\n",
    "    cursor.execute(sql_insert,(record['batch_id'], record['starting_frame_id'], record['ending_frame_id'],record['timestamp']))\n",
    "\n",
    "# Commit the transaction\n",
    "conncetion.commit()\n",
    "\n",
    "\n",
    "# Close the cursor and connection\n",
    "cursor.close()\n",
    "conncetion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loging and Error Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Error Handling and Logging\n",
    "Implement error handling and logging mechanisms in your code to capture and handle\n",
    "exceptions that may occur during frame processing, data storage, or transmission.\n",
    "Ensure that the code logs relevant information for debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, Logging is done by expecting each function above class \"videostreaming\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "\n",
    "class FrameProcessor:\n",
    "    def __init__(self, camera_id, geo_location, output_folder, duration):\n",
    "        self.camera_id = camera_id\n",
    "        self.geo_location = geo_location\n",
    "        self.output_folder = output_folder\n",
    "        self.duration = duration  \n",
    "        self.frame_id = 0\n",
    "        self.current_batch = None\n",
    "\n",
    "        # Create the output folder if it doesn't exist\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        # Initialize JSON data list and batch list\n",
    "        self.json_data = []\n",
    "        self.batches = []\n",
    "\n",
    "        # Initialize logging\n",
    "        self.logger = self.setup_logger()\n",
    "\n",
    "    def setup_logger(self):\n",
    "        logger = logging.getLogger(\"frame_processor\")\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "\n",
    "        # Create a file handler and set the log level\n",
    "        log_file = os.path.join(self.output_folder, \"frame_processor.log\")\n",
    "        file_handler = logging.FileHandler(log_file)\n",
    "        file_handler.setLevel(logging.DEBUG)\n",
    "\n",
    "        # Create a console handler and set the log level\n",
    "        console_handler = logging.StreamHandler()\n",
    "        console_handler.setLevel(logging.INFO)\n",
    "\n",
    "        # Create a formatter and set it for the handlers\n",
    "        formatter = logging.Formatter(\n",
    "            \"%(asctime)s [%(levelname)s] %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "        file_handler.setFormatter(formatter)\n",
    "        console_handler.setFormatter(formatter)\n",
    "\n",
    "        # Add the handlers to the logger\n",
    "        logger.addHandler(file_handler)\n",
    "        logger.addHandler(console_handler)\n",
    "\n",
    "        return logger\n",
    "\n",
    "    def process_frame(self, frame, timestamp):\n",
    "        try:\n",
    "            # Write one frame per second as an image file\n",
    "            if self.frame_id % 25 == 0:\n",
    "                image_filename = os.path.join(self.output_folder, f\"frame_{self.frame_id // 25}.jpg\")\n",
    "                cv2.imwrite(image_filename, frame)\n",
    "\n",
    "            # Create JSON object for the frame\n",
    "            frame_info = {\n",
    "                \"camera_id\": self.camera_id,\n",
    "                \"frame_id\": self.frame_id,\n",
    "                \"geo_location\": self.geo_location,\n",
    "                \"image_path\": os.path.abspath(image_filename),\n",
    "                \"timestamp\": timestamp,\n",
    "            }\n",
    "\n",
    "            # Append frame info to the JSON data list\n",
    "            self.json_data.append(frame_info)\n",
    "\n",
    "            # Check if a new batch needs to be created\n",
    "            if self.current_batch is None or timestamp - self.current_batch[\"timestamp\"] >= self.duration:\n",
    "                self.create_new_batch()\n",
    "\n",
    "            # Increment frame ID\n",
    "            self.frame_id += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing frame: {str(e)}\")\n",
    "\n",
    "    def create_new_batch(self):\n",
    "        try:\n",
    "            # Create a new batch dictionary\n",
    "            batch_id = len(self.batches) + 1\n",
    "            starting_frame_id = self.frame_id - 25  # Start of the last second\n",
    "            ending_frame_id = self.frame_id - 1  # End of the last second\n",
    "            timestamp = time.time()\n",
    "\n",
    "            batch_info = {\n",
    "                \"batch_id\": batch_id,\n",
    "                \"starting_frame_id\": starting_frame_id,\n",
    "                \"ending_frame_id\": ending_frame_id,\n",
    "                \"timestamp\": timestamp,\n",
    "            }\n",
    "\n",
    "            # Append batch info to the batch list\n",
    "            self.batches.append(batch_info)\n",
    "\n",
    "            # Update the current batch\n",
    "            self.current_batch = batch_info\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error creating new batch: {str(e)}\")\n",
    "\n",
    "    def save_json_data(self, json_filename):\n",
    "        try:\n",
    "            # Write JSON data to a JSON file\n",
    "            with open(json_filename, \"w\") as json_file:\n",
    "                json.dump(self.json_data, json_file, indent=4)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error saving JSON data: {str(e)}\")\n",
    "\n",
    "    def save_batch_info(self, batch_filename):\n",
    "        try:\n",
    "            # Write batch information to a JSON file\n",
    "            with open(batch_filename, \"w\") as batch_file:\n",
    "                json.dump(self.batches, batch_file, indent=4)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error saving batch information: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage:\n",
    "    camera_id = \"camera1\"\n",
    "    geo_location = \"latitude: 123.456, longitude: 789.012\"\n",
    "    output_folder = \"output_frames\"\n",
    "    json_filename = \"frame_info.json\"\n",
    "    batch_filename = \"batch_info.json\"\n",
    "    duration = 10  # Duration of each batch in seconds\n",
    "\n",
    "    frame_processor = FrameProcessor(camera_id, geo_location, output_folder, duration)\n",
    "\n",
    "    # Simulated video capture (you can replace this with your actual video capture logic)\n",
    "    cap = cv2.VideoCapture(\"sample_video.mp4\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        timestamp = time.time()\n",
    "        frame_processor.process_frame(frame, timestamp)\n",
    "\n",
    "    frame_processor.save_json_data(json_filename)\n",
    "    frame_processor.save_batch_info(batch_filename)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Concurrency and Performance\n",
    "\n",
    "To improve performance, modify your code to handle multiple camera streams\n",
    "concurrently. Consider there are 2 live streams and enable concurrent processing of\n",
    "those frames in the application. Explain how you ensure thread safety and avoid race\n",
    "conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, It accepts two cameras from system as same code followed above from above VideoStream class. Some slight changes added to increase code when run with both cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import pyodbc\n",
    "\n",
    "\n",
    "class img_stream_process:\n",
    "    def __init__(self, camera_id, geo_location, output_folder,output_folder1, config_filename):\n",
    "        self.camera_id = camera_id\n",
    "        self.geo_location = geo_location\n",
    "        self.output_folder = output_folder\n",
    "        self.frame_id = 0\n",
    "        self.cap1 = cv2.VideoCapture(camera_id[0])\n",
    "        self.cap2 = cv2.VideoCapture(camera_id[1])\n",
    "        self.config_filename = config_filename\n",
    "        self.batch_duration = self.read_config_duration()[0]\n",
    "        self.batch_size = self.read_config_duration()[1]\n",
    "        \n",
    "\n",
    "        # Create the output folder\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        os.makedirs(output_folder1, exist_ok=True)\n",
    "\n",
    "\n",
    "        #JSON data list and batch list\n",
    "        self.json_data = []\n",
    "        self.batches = []\n",
    "\n",
    "    def read_config_duration(self):\n",
    "        # Read the duration from the config file\n",
    "        with open(self.config_filename, \"r\") as config_file:\n",
    "            config_data = json.load(config_file)\n",
    "            duration = config_data.get(\"duration\")\n",
    "            batch_size = config_data.get(\"batch_size\")\n",
    "        return duration,batch_size\n",
    "\n",
    "    def video_capture(self):\n",
    "        # Check if the video stream was opened successfully\n",
    "        if not self.cap1.isOpened():\n",
    "            print(\"Error: Could not open video source.\")\n",
    "            exit()\n",
    "        if not self.cap2.isOpened():\n",
    "            print(\"Error: Could not open video source.\")\n",
    "            exit()\n",
    "\n",
    "    def frame_processing(self):\n",
    "        # Set the desired frames per second (fps)\n",
    "        desired_fps = 25\n",
    "\n",
    "        frame_count = 0\n",
    "        frame_to_save1 = None  \n",
    "        frame_to_save2 = None\n",
    "\n",
    "        while True:\n",
    "            # Read a frame from the video stream\n",
    "            ret1, frame1 = self.cap1.read()\n",
    "            ret2,frame2 = self.cap2.read()\n",
    "\n",
    "            # Check if the frame was successfully read\n",
    "            if not ret1:\n",
    "                print(\"Error: Could not read frame.\")\n",
    "                break\n",
    "            if not ret2:\n",
    "                print(\"Error: Could not read frame.\")\n",
    "                break\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "            # Save one frame per second as an image file\n",
    "            if frame_count % desired_fps == 0:\n",
    "                outframe_id = (frame_count // desired_fps)\n",
    "                frame_to_save1 = frame1  # Save the frame to be reused\n",
    "                frame_to_save2 = frame2\n",
    "                frame_filename1 = os.path.join(self.output_folder, f\"frame_{outframe_id}.jpg\")\n",
    "                frame_filename2 = os.path.join(self.output_folder1, f\"frame_{outframe_id}.jpg\")\n",
    "\n",
    "                cv2.imwrite(frame_filename1, frame_to_save1)  # Save the frame as an image\n",
    "                cv2.imwrite(frame_filename2, frame_to_save2)  # Save the frame as an image\n",
    "\n",
    "\n",
    "                # Append frame info to the JSON data list\n",
    "                frame_info1 = {\n",
    "                    \"camera_id\": self.camera_id[0],\n",
    "                    \"frame_id\": outframe_id,\n",
    "                    \"geo_location\": self.geo_location,\n",
    "                    \"image_path\": frame_filename1\n",
    "                }\n",
    "                frame_info2 = {\n",
    "                    \"camera_id\": self.camera_id[1],\n",
    "                    \"frame_id\": outframe_id,\n",
    "                    \"geo_location\": self.geo_location,\n",
    "                    \"image_path\": frame_filename2\n",
    "                }\n",
    "                self.json_data.append(frame_info1)\n",
    "                self.json_data.append(frame_info2)\n",
    "\n",
    "\n",
    "            # Reuse the saved frame for the next 24 frames within the same second\n",
    "            if frame_to_save1 is not None:\n",
    "                cv2.imshow(\"Frame\", frame_to_save1)\n",
    "\n",
    "            # Exit the loop when the 'q' key is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            # Release the video capture object and close any open windows\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def batch_frames(self):     \n",
    "    # Calculate the number of batches.\n",
    "        num_batches = math.ceil(self.batch_duration / self.batch_size)\n",
    "\n",
    "    # Create a dictionary for each batch.\n",
    "        #batches = {}\n",
    "        for i in range(num_batches):\n",
    "            batch_id = i + 1\n",
    "\n",
    "        # Calculate the starting and ending frame IDs for the batch.\n",
    "            starting_frame_id = batch_id * self.batch_size - self.batch_size + 1\n",
    "            ending_frame_id = min(starting_frame_id + self.batch_size - 1, self.batch_duration)\n",
    "\n",
    "        # Calculate the timestamp of the batch.\n",
    "            timestamp = starting_frame_id / self.batch_duration\n",
    "        #timestamp = time.time()\n",
    "\n",
    "        # Add the batch to the dictionary.\n",
    "            batch = {\n",
    "            \"batch_id\": batch_id,\n",
    "            \"starting_frame_id\": starting_frame_id,\n",
    "            \"ending_frame_id\": ending_frame_id,\n",
    "            \"timestamp\": timestamp\n",
    "            }\n",
    "            self.batches.append(batch)\n",
    "            return self.batches\n",
    "    def sqlserver_db(self):\n",
    "        conn = psycopg2.connect(dbname=\"videostream\",user=\"postgres\",password=\"leo@#838\",host=\"localhost\",port=5432)\n",
    "        cursor = conn.cursor()\n",
    "        print(self.batches[0].values())\n",
    "\n",
    "        \n",
    "    def save_json_data(self, json_filename):\n",
    "        # Write JSON data to a JSON file\n",
    "        with open(json_filename, \"w\") as json_file:\n",
    "            json.dump(self.json_data, json_file, indent=4)\n",
    "\n",
    "    def save_batch_info(self, batch_filename):\n",
    "        with open(batch_filename, \"w\") as batch_file:\n",
    "            json.dump(self.batches, batch_file, indent=4)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    camera_id = 0\n",
    "    geo_location = \"latitude: 123.456, longitude: 789.012\"\n",
    "    output_folder = \"output_frames\"\n",
    "    output_folder1 = \"outframes\"\n",
    "    config_filename = \"config.json\"\n",
    "    json_filename = \"frame_info.json\"\n",
    "    batch_filename = \"batch_info.json\"\n",
    "\n",
    "    processor = img_stream_process(camera_id, geo_location, output_folder,output_folder1, config_filename)\n",
    "    processor.video_capture()\n",
    "    processor.frame_processing()\n",
    "    processor.batch_frames()\n",
    "    processor.save_json_data(json_filename)\n",
    "    processor.save_batch_info(batch_filename)\n",
    "\n",
    "\n",
    "    print(\"Frame processing and batching complete. JSON data saved to:\", json_filename)\n",
    "    print(\"Batch information saved to:\", batch_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2:\n",
    "1. Write a user driven python program that accepts,\n",
    "\n",
    "âž¢ TIMESTAMP\n",
    "âž¢ DURATION OF THE VIDEO FILE from the user.\n",
    "Based on the above information, iterate through the batch information in the Database. Create a\n",
    "metadata out of it which will be helpful in gathering the frame information from the json file.\n",
    "Once the necessary frames are gathered convert them to a mp4 file and present them to the\n",
    "user.\n",
    "\n",
    "\n",
    "2. Error Handling and Logging\n",
    "Implement error handling and logging mechanisms in your code to capture and handle\n",
    "exceptions that may occur during frame processing, data storage, or transmission. Ensure that\n",
    "the code logs relevant information for debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is same as task one but timestamp and duration by user can be taken by input() in class. Create respective metadata and generate a video from the frames infomation present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import pyodbc\n",
    "\n",
    "\n",
    "class img_stream_process:\n",
    "    def __init__(self, camera_id, geo_location, output_folder, config_filename):\n",
    "        self.camera_id = camera_id\n",
    "        self.geo_location = geo_location\n",
    "        self.output_folder = output_folder\n",
    "        self.frame_id = 0\n",
    "        self.cap = cv2.VideoCapture(camera_id)\n",
    "        self.config_filename = config_filename\n",
    "        #video duration\n",
    "        self.batch_duration = int(input())\n",
    "        #batch size\n",
    "        self.batch_size = int(input())\n",
    "        \n",
    "\n",
    "        # Create the output folder\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        #JSON data list and batch list\n",
    "        self.json_data = []\n",
    "        self.batches = []\n",
    "\n",
    "    def video_capture(self):\n",
    "        # Check if the video stream was opened successfully\n",
    "        if not self.cap.isOpened():\n",
    "            print(\"Error: Could not open video source.\")\n",
    "            exit()\n",
    "\n",
    "    def frame_processing(self):\n",
    "        # Set the desired frames per second (fps)\n",
    "        desired_fps = 25\n",
    "\n",
    "        frame_count = 0\n",
    "        frame_to_save = None\n",
    "\n",
    "        while True:\n",
    "            # Read a frame from the video stream\n",
    "            ret, frame = self.cap.read()\n",
    "\n",
    "            # Check if the frame was successfully read\n",
    "            if not ret:\n",
    "                print(\"Error: Could not read frame.\")\n",
    "                break\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "            # Save one frame per second as an image file\n",
    "            if frame_count % desired_fps == 0:\n",
    "                outframe_id = (frame_count // desired_fps)\n",
    "                frame_to_save = frame  # Save the frame to be reused\n",
    "                frame_filename = os.path.join(self.output_folder, f\"frame_{outframe_id}.jpg\")\n",
    "                cv2.imwrite(frame_filename, frame_to_save)  # Save the frame as an image\n",
    "\n",
    "                # Append frame info to the JSON data list\n",
    "                frame_info = {\n",
    "                    \"camera_id\": self.camera_id,\n",
    "                    \"frame_id\": outframe_id,\n",
    "                    \"geo_location\": self.geo_location,\n",
    "                    \"image_path\": frame_filename\n",
    "                }\n",
    "                self.json_data.append(frame_info)\n",
    "\n",
    "            # Reuse the saved frame for the next 24 frames within the same second\n",
    "            if frame_to_save is not None:\n",
    "                cv2.imshow(\"Frame\", frame_to_save)\n",
    "\n",
    "            # Exit the loop when the 'q' key is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            # Release the video capture object and close any open windows\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def batch_frames(self):     \n",
    "    # Calculate the number of batches.\n",
    "        num_batches = math.ceil(self.batch_duration / self.batch_size)\n",
    "\n",
    "    # Create a dictionary for each batch.\n",
    "        #batches = {}\n",
    "        for i in range(num_batches):\n",
    "            batch_id = i + 1\n",
    "\n",
    "        # Calculate the starting and ending frame IDs for the batch.\n",
    "            starting_frame_id = batch_id * self.batch_size - self.batch_size + 1\n",
    "            ending_frame_id = min(starting_frame_id + self.batch_size - 1, self.batch_duration)\n",
    "\n",
    "        # Calculate the timestamp of the batch.\n",
    "            timestamp = starting_frame_id / self.batch_duration\n",
    "        #timestamp = time.time()\n",
    "\n",
    "        # Add the batch to the dictionary.\n",
    "            batch = {\n",
    "            \"batch_id\": batch_id,\n",
    "            \"starting_frame_id\": starting_frame_id,\n",
    "            \"ending_frame_id\": ending_frame_id,\n",
    "            \"timestamp\": timestamp\n",
    "            }\n",
    "            self.batches.append(batch)\n",
    "            return self.batches\n",
    "    def sqlserver_db(self):\n",
    "        conn = psycopg2.connect(dbname=\"videostream\",user=\"postgres\",password=\"leo@#838\",host=\"localhost\",port=5432)\n",
    "        cursor = conn.cursor()\n",
    "        print(self.batches[0].values())\n",
    "\n",
    "        \n",
    "    def save_json_data(self, json_filename):\n",
    "        # Write JSON data to a JSON file\n",
    "        with open(json_filename, \"w\") as json_file:\n",
    "            json.dump(self.json_data, json_file, indent=4)\n",
    "\n",
    "    def save_batch_info(self, batch_filename):\n",
    "        with open(batch_filename, \"w\") as batch_file:\n",
    "            json.dump(self.batches, batch_file, indent=4)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    camera_id = 0\n",
    "    geo_location = \"latitude: 123.456, longitude: 789.012\"\n",
    "    output_folder = \"output_frames\"\n",
    "    config_filename = \"config.json\"\n",
    "    json_filename = \"frame_info.json\"\n",
    "    batch_filename = \"batch_info.json\"\n",
    "\n",
    "    processor = img_stream_process(camera_id, geo_location, output_folder, config_filename)\n",
    "    processor.video_capture()\n",
    "    processor.frame_processing()\n",
    "    processor.batch_frames()\n",
    "    processor.sqlserver_db()\n",
    "    processor.save_json_data(json_filename)\n",
    "    processor.save_batch_info(batch_filename)\n",
    "\n",
    "\n",
    "    print(json_filename)\n",
    "    print(batch_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "width = 650\n",
    "height = 650\n",
    "\n",
    "# Load the frame metadata from the JSON file\n",
    "with open(\"frame_info.json\", \"r\") as json_file:\n",
    "    frame_metadata = json.load(json_file)\n",
    "\n",
    "# Create a VideoWriter object to save the compiled video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mkvv')  # Codec for MP4 format\n",
    "output_video = cv2.VideoWriter(\"output_video.mkv\", fourcc, 25, (width, height))  # Adjust width and height\n",
    "\n",
    "# Loop through the frame metadata and add frames to the video\n",
    "for frame_info in frame_metadata:\n",
    "    frame = cv2.imread(frame_info[\"image_path\"])  # Load the frame image\n",
    "    output_video.write(frame)\n",
    "\n",
    "# Release the VideoWriter\n",
    "output_video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chara\\AppData\\Local\\Temp\\ipykernel_14068\\1473770905.py:13: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  frame = imageio.imread(frame_info[\"image_path\"])  # Load the frame image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to output_video.mp4\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import json\n",
    "\n",
    "# Load the frame metadata from the JSON file\n",
    "with open(\"frame_info.json\", \"r\") as json_file:\n",
    "    frame_metadata = json.load(json_file)\n",
    "\n",
    "# Create a list to store frames\n",
    "frames = []\n",
    "\n",
    "# Loop through the frame metadata and add frames to the list\n",
    "for frame_info in frame_metadata:\n",
    "    frame = imageio.imread(frame_info[\"image_path\"])  # Load the frame image\n",
    "    frames.append(frame)\n",
    "\n",
    "# Define the output video file path\n",
    "output_video_path = \"output_video.mp4\"\n",
    "\n",
    "# Create the MP4 video from the list of frames\n",
    "imageio.mimsave(output_video_path, frames, fps=25)  # Adjust the frame rate (fps) as needed\n",
    "\n",
    "print(f\"Video saved to {output_video_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
